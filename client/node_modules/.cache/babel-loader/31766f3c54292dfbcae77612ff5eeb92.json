{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.GridFSBucketWriteStream = void 0;\n\nconst stream_1 = require(\"stream\");\n\nconst bson_1 = require(\"../bson\");\n\nconst error_1 = require(\"../error\");\n\nconst utils_1 = require(\"../utils\");\n\nconst write_concern_1 = require(\"./../write_concern\");\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\n\n\nclass GridFSBucketWriteStream extends stream_1.Writable {\n  /** @internal\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   */\n  constructor(bucket, filename, options) {\n    super();\n    options = options !== null && options !== void 0 ? options : {};\n    this.bucket = bucket;\n    this.chunks = bucket.s._chunksCollection;\n    this.filename = filename;\n    this.files = bucket.s._filesCollection;\n    this.options = options;\n    this.writeConcern = write_concern_1.WriteConcern.fromOptions(options) || bucket.s.options.writeConcern; // Signals the write is all done\n\n    this.done = false;\n    this.id = options.id ? options.id : new bson_1.ObjectId(); // properly inherit the default chunksize from parent\n\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n    this.length = 0;\n    this.n = 0;\n    this.pos = 0;\n    this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n\n    if (!this.bucket.s.calledOpenUploadStream) {\n      this.bucket.s.calledOpenUploadStream = true;\n      checkIndexes(this, () => {\n        this.bucket.s.checkedIndexes = true;\n        this.bucket.emit('index');\n      });\n    }\n  }\n\n  write(chunk, encodingOrCallback, callback) {\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback = typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n    return waitForIndexes(this, () => doWrite(this, chunk, encoding, callback));\n  }\n\n  abort(callback) {\n    return (0, utils_1.maybePromise)(callback, callback => {\n      if (this.state.streamEnd) {\n        // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n        return callback(new error_1.MongoAPIError('Cannot abort a stream that has already completed'));\n      }\n\n      if (this.state.aborted) {\n        // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n        return callback(new error_1.MongoAPIError('Cannot call abort() on a stream twice'));\n      }\n\n      this.state.aborted = true;\n      this.chunks.deleteMany({\n        files_id: this.id\n      }, error => callback(error));\n    });\n  }\n\n  end(chunkOrCallback, encodingOrCallback, callback) {\n    const chunk = typeof chunkOrCallback === 'function' ? undefined : chunkOrCallback;\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback = typeof chunkOrCallback === 'function' ? chunkOrCallback : typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n    if (checkAborted(this, callback)) return this;\n    this.state.streamEnd = true;\n\n    if (callback) {\n      this.once(GridFSBucketWriteStream.FINISH, result => {\n        if (callback) callback(undefined, result);\n      });\n    }\n\n    if (!chunk) {\n      waitForIndexes(this, () => !!writeRemnant(this));\n      return this;\n    }\n\n    this.write(chunk, encoding, () => {\n      writeRemnant(this);\n    });\n    return this;\n  }\n\n}\n\nexports.GridFSBucketWriteStream = GridFSBucketWriteStream;\n/** @event */\n\nGridFSBucketWriteStream.CLOSE = 'close';\n/** @event */\n\nGridFSBucketWriteStream.ERROR = 'error';\n/**\n * `end()` was called and the write stream successfully wrote the file metadata and all the chunks to MongoDB.\n * @event\n */\n\nGridFSBucketWriteStream.FINISH = 'finish';\n\nfunction __handleError(stream, error, callback) {\n  if (stream.state.errored) {\n    return;\n  }\n\n  stream.state.errored = true;\n\n  if (callback) {\n    return callback(error);\n  }\n\n  stream.emit(GridFSBucketWriteStream.ERROR, error);\n}\n\nfunction createChunkDoc(filesId, n, data) {\n  return {\n    _id: new bson_1.ObjectId(),\n    files_id: filesId,\n    n,\n    data\n  };\n}\n\nfunction checkChunksIndex(stream, callback) {\n  stream.chunks.listIndexes().toArray((error, indexes) => {\n    let index;\n\n    if (error) {\n      // Collection doesn't exist so create index\n      if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n        index = {\n          files_id: 1,\n          n: 1\n        };\n        stream.chunks.createIndex(index, {\n          background: false,\n          unique: true\n        }, error => {\n          if (error) {\n            return callback(error);\n          }\n\n          callback();\n        });\n        return;\n      }\n\n      return callback(error);\n    }\n\n    let hasChunksIndex = false;\n\n    if (indexes) {\n      indexes.forEach(index => {\n        if (index.key) {\n          const keys = Object.keys(index.key);\n\n          if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n            hasChunksIndex = true;\n          }\n        }\n      });\n    }\n\n    if (hasChunksIndex) {\n      callback();\n    } else {\n      index = {\n        files_id: 1,\n        n: 1\n      };\n      const writeConcernOptions = getWriteOptions(stream);\n      stream.chunks.createIndex(index, { ...writeConcernOptions,\n        background: true,\n        unique: true\n      }, callback);\n    }\n  });\n}\n\nfunction checkDone(stream, callback) {\n  if (stream.done) return true;\n\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true; // Create a new files doc\n\n    const filesDoc = createFilesDoc(stream.id, stream.length, stream.chunkSizeBytes, stream.filename, stream.options.contentType, stream.options.aliases, stream.options.metadata);\n\n    if (checkAborted(stream, callback)) {\n      return false;\n    }\n\n    stream.files.insertOne(filesDoc, getWriteOptions(stream), error => {\n      if (error) {\n        return __handleError(stream, error, callback);\n      }\n\n      stream.emit(GridFSBucketWriteStream.FINISH, filesDoc);\n      stream.emit(GridFSBucketWriteStream.CLOSE);\n    });\n    return true;\n  }\n\n  return false;\n}\n\nfunction checkIndexes(stream, callback) {\n  stream.files.findOne({}, {\n    projection: {\n      _id: 1\n    }\n  }, (error, doc) => {\n    if (error) {\n      return callback(error);\n    }\n\n    if (doc) {\n      return callback();\n    }\n\n    stream.files.listIndexes().toArray((error, indexes) => {\n      let index;\n\n      if (error) {\n        // Collection doesn't exist so create index\n        if (error instanceof error_1.MongoError && error.code === error_1.MONGODB_ERROR_CODES.NamespaceNotFound) {\n          index = {\n            filename: 1,\n            uploadDate: 1\n          };\n          stream.files.createIndex(index, {\n            background: false\n          }, error => {\n            if (error) {\n              return callback(error);\n            }\n\n            checkChunksIndex(stream, callback);\n          });\n          return;\n        }\n\n        return callback(error);\n      }\n\n      let hasFileIndex = false;\n\n      if (indexes) {\n        indexes.forEach(index => {\n          const keys = Object.keys(index.key);\n\n          if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n            hasFileIndex = true;\n          }\n        });\n      }\n\n      if (hasFileIndex) {\n        checkChunksIndex(stream, callback);\n      } else {\n        index = {\n          filename: 1,\n          uploadDate: 1\n        };\n        const writeConcernOptions = getWriteOptions(stream);\n        stream.files.createIndex(index, { ...writeConcernOptions,\n          background: false\n        }, error => {\n          if (error) {\n            return callback(error);\n          }\n\n          checkChunksIndex(stream, callback);\n        });\n      }\n    });\n  });\n}\n\nfunction createFilesDoc(_id, length, chunkSize, filename, contentType, aliases, metadata) {\n  const ret = {\n    _id,\n    length,\n    chunkSize,\n    uploadDate: new Date(),\n    filename\n  };\n\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, chunk, encoding, callback) {\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n  stream.length += inputBuf.length; // Input is small enough to fit in our buffer\n\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n    callback && callback(); // Note that we reverse the typical semantics of write's return value\n    // to be compatible with node's `.pipe()` function.\n    // True means client can keep writing.\n\n    return true;\n  } // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n\n\n  let inputBufRemaining = inputBuf.length;\n  let spaceRemaining = stream.chunkSizeBytes - stream.pos;\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  let outstandingRequests = 0;\n\n  while (inputBufRemaining > 0) {\n    const inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    let doc;\n\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n\n      if (checkAborted(stream, callback)) {\n        return false;\n      }\n\n      stream.chunks.insertOne(doc, getWriteOptions(stream), error => {\n        if (error) {\n          return __handleError(stream, error);\n        }\n\n        --stream.state.outstandingRequests;\n        --outstandingRequests;\n\n        if (!outstandingRequests) {\n          stream.emit('drain', doc);\n          callback && callback();\n          checkDone(stream);\n        }\n      });\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  } // Note that we reverse the typical semantics of write's return value\n  // to be compatible with node's `.pipe()` function.\n  // False means the client should wait for the 'drain' event.\n\n\n  return false;\n}\n\nfunction getWriteOptions(stream) {\n  const obj = {};\n\n  if (stream.writeConcern) {\n    obj.writeConcern = {\n      w: stream.writeConcern.w,\n      wtimeout: stream.writeConcern.wtimeout,\n      j: stream.writeConcern.j\n    };\n  }\n\n  return obj;\n}\n\nfunction waitForIndexes(stream, callback) {\n  if (stream.bucket.s.checkedIndexes) {\n    return callback(false);\n  }\n\n  stream.bucket.once('index', () => {\n    callback(true);\n  });\n  return true;\n}\n\nfunction writeRemnant(stream, callback) {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n\n  ++stream.state.outstandingRequests; // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n\n  const remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  const doc = createChunkDoc(stream.id, stream.n, remnant); // If the stream was aborted, do not write remnant\n\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n\n  stream.chunks.insertOne(doc, getWriteOptions(stream), error => {\n    if (error) {\n      return __handleError(stream, error);\n    }\n\n    --stream.state.outstandingRequests;\n    checkDone(stream);\n  });\n  return true;\n}\n\nfunction checkAborted(stream, callback) {\n  if (stream.state.aborted) {\n    if (typeof callback === 'function') {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n      callback(new error_1.MongoAPIError('Stream has been aborted'));\n    }\n\n    return true;\n  }\n\n  return false;\n}","map":{"version":3,"mappings":";;;;;;;AAAA;;AAGA;;AAEA;;AACA;;AAEA;AA0BA;;;;;;;;AAMA,MAAaA,uBAAb,SAA6CC,iBAA7C,CAAqD;AA+BnD;;;;;AAKAC,cAAYC,MAAZ,EAAkCC,QAAlC,EAAoDC,OAApD,EAA4F;AAC1F;AAEAA,WAAO,GAAGA,OAAO,SAAP,WAAO,WAAP,aAAW,EAArB;AACA,SAAKF,MAAL,GAAcA,MAAd;AACA,SAAKG,MAAL,GAAcH,MAAM,CAACI,CAAP,CAASC,iBAAvB;AACA,SAAKJ,QAAL,GAAgBA,QAAhB;AACA,SAAKK,KAAL,GAAaN,MAAM,CAACI,CAAP,CAASG,gBAAtB;AACA,SAAKL,OAAL,GAAeA,OAAf;AACA,SAAKM,YAAL,GAAoBC,6BAAaC,WAAb,CAAyBR,OAAzB,KAAqCF,MAAM,CAACI,CAAP,CAASF,OAAT,CAAiBM,YAA1E,CAT0F,CAU1F;;AACA,SAAKG,IAAL,GAAY,KAAZ;AAEA,SAAKC,EAAL,GAAUV,OAAO,CAACU,EAAR,GAAaV,OAAO,CAACU,EAArB,GAA0B,IAAIC,eAAJ,EAApC,CAb0F,CAc1F;;AACA,SAAKC,cAAL,GAAsBZ,OAAO,CAACY,cAAR,IAA0B,KAAKd,MAAL,CAAYI,CAAZ,CAAcF,OAAd,CAAsBY,cAAtE;AACA,SAAKC,UAAL,GAAkBC,MAAM,CAACC,KAAP,CAAa,KAAKH,cAAlB,CAAlB;AACA,SAAKI,MAAL,GAAc,CAAd;AACA,SAAKC,CAAL,GAAS,CAAT;AACA,SAAKC,GAAL,GAAW,CAAX;AACA,SAAKC,KAAL,GAAa;AACXC,eAAS,EAAE,KADA;AAEXC,yBAAmB,EAAE,CAFV;AAGXC,aAAO,EAAE,KAHE;AAIXC,aAAO,EAAE;AAJE,KAAb;;AAOA,QAAI,CAAC,KAAKzB,MAAL,CAAYI,CAAZ,CAAcsB,sBAAnB,EAA2C;AACzC,WAAK1B,MAAL,CAAYI,CAAZ,CAAcsB,sBAAd,GAAuC,IAAvC;AAEAC,kBAAY,CAAC,IAAD,EAAO,MAAK;AACtB,aAAK3B,MAAL,CAAYI,CAAZ,CAAcwB,cAAd,GAA+B,IAA/B;AACA,aAAK5B,MAAL,CAAY6B,IAAZ,CAAiB,OAAjB;AACD,OAHW,CAAZ;AAID;AACF;;AAkBDC,OAAK,CACHC,KADG,EAEHC,kBAFG,EAGHC,QAHG,EAGsB;AAEzB,UAAMC,QAAQ,GAAG,OAAOF,kBAAP,KAA8B,UAA9B,GAA2CG,SAA3C,GAAuDH,kBAAxE;AACAC,YAAQ,GAAG,OAAOD,kBAAP,KAA8B,UAA9B,GAA2CA,kBAA3C,GAAgEC,QAA3E;AACA,WAAOG,cAAc,CAAC,IAAD,EAAO,MAAMC,OAAO,CAAC,IAAD,EAAON,KAAP,EAAcG,QAAd,EAAwBD,QAAxB,CAApB,CAArB;AACD;;AAWDK,OAAK,CAACL,QAAD,EAA0B;AAC7B,WAAO,0BAAaA,QAAb,EAAuBA,QAAQ,IAAG;AACvC,UAAI,KAAKZ,KAAL,CAAWC,SAAf,EAA0B;AACxB;AACA,eAAOW,QAAQ,CAAC,IAAIM,qBAAJ,CAAkB,kDAAlB,CAAD,CAAf;AACD;;AAED,UAAI,KAAKlB,KAAL,CAAWI,OAAf,EAAwB;AACtB;AACA,eAAOQ,QAAQ,CAAC,IAAIM,qBAAJ,CAAkB,uCAAlB,CAAD,CAAf;AACD;;AAED,WAAKlB,KAAL,CAAWI,OAAX,GAAqB,IAArB;AACA,WAAKtB,MAAL,CAAYqC,UAAZ,CAAuB;AAAEC,gBAAQ,EAAE,KAAK7B;AAAjB,OAAvB,EAA8C8B,KAAK,IAAIT,QAAQ,CAACS,KAAD,CAA/D;AACD,KAbM,CAAP;AAcD;;AAqBDC,KAAG,CACDC,eADC,EAEDZ,kBAFC,EAGDC,QAHC,EAGqC;AAEtC,UAAMF,KAAK,GAAG,OAAOa,eAAP,KAA2B,UAA3B,GAAwCT,SAAxC,GAAoDS,eAAlE;AACA,UAAMV,QAAQ,GAAG,OAAOF,kBAAP,KAA8B,UAA9B,GAA2CG,SAA3C,GAAuDH,kBAAxE;AACAC,YAAQ,GACN,OAAOW,eAAP,KAA2B,UAA3B,GACIA,eADJ,GAEI,OAAOZ,kBAAP,KAA8B,UAA9B,GACAA,kBADA,GAEAC,QALN;AAOA,QAAIY,YAAY,CAAC,IAAD,EAAOZ,QAAP,CAAhB,EAAkC,OAAO,IAAP;AAElC,SAAKZ,KAAL,CAAWC,SAAX,GAAuB,IAAvB;;AAEA,QAAIW,QAAJ,EAAc;AACZ,WAAKa,IAAL,CAAUjD,uBAAuB,CAACkD,MAAlC,EAA2CC,MAAD,IAAuB;AAC/D,YAAIf,QAAJ,EAAcA,QAAQ,CAACE,SAAD,EAAYa,MAAZ,CAAR;AACf,OAFD;AAGD;;AAED,QAAI,CAACjB,KAAL,EAAY;AACVK,oBAAc,CAAC,IAAD,EAAO,MAAM,CAAC,CAACa,YAAY,CAAC,IAAD,CAA3B,CAAd;AACA,aAAO,IAAP;AACD;;AAED,SAAKnB,KAAL,CAAWC,KAAX,EAAkBG,QAAlB,EAA4B,MAAK;AAC/Be,kBAAY,CAAC,IAAD,CAAZ;AACD,KAFD;AAIA,WAAO,IAAP;AACD;;AAlLkD;;AAArDC;AAqBE;;AACgBrD,gCAAQ,OAAR;AAChB;;AACgBA,gCAAQ,OAAR;AAChB;;;;;AAIgBA,iCAAS,QAAT;;AAwJlB,SAASsD,aAAT,CACEC,MADF,EAEEV,KAFF,EAGET,QAHF,EAGqB;AAEnB,MAAImB,MAAM,CAAC/B,KAAP,CAAaG,OAAjB,EAA0B;AACxB;AACD;;AACD4B,QAAM,CAAC/B,KAAP,CAAaG,OAAb,GAAuB,IAAvB;;AACA,MAAIS,QAAJ,EAAc;AACZ,WAAOA,QAAQ,CAACS,KAAD,CAAf;AACD;;AACDU,QAAM,CAACvB,IAAP,CAAYhC,uBAAuB,CAACwD,KAApC,EAA2CX,KAA3C;AACD;;AAED,SAASY,cAAT,CAAwBC,OAAxB,EAA2CpC,CAA3C,EAAsDqC,IAAtD,EAAkE;AAChE,SAAO;AACLC,OAAG,EAAE,IAAI5C,eAAJ,EADA;AAEL4B,YAAQ,EAAEc,OAFL;AAGLpC,KAHK;AAILqC;AAJK,GAAP;AAMD;;AAED,SAASE,gBAAT,CAA0BN,MAA1B,EAA2DnB,QAA3D,EAA6E;AAC3EmB,QAAM,CAACjD,MAAP,CAAcwD,WAAd,GAA4BC,OAA5B,CAAoC,CAAClB,KAAD,EAAmBmB,OAAnB,KAA2C;AAC7E,QAAIC,KAAJ;;AACA,QAAIpB,KAAJ,EAAW;AACT;AACA,UAAIA,KAAK,YAAYH,kBAAjB,IAA+BG,KAAK,CAACqB,IAAN,KAAexB,4BAAoByB,iBAAtE,EAAyF;AACvFF,aAAK,GAAG;AAAErB,kBAAQ,EAAE,CAAZ;AAAetB,WAAC,EAAE;AAAlB,SAAR;AACAiC,cAAM,CAACjD,MAAP,CAAc8D,WAAd,CAA0BH,KAA1B,EAAiC;AAAEI,oBAAU,EAAE,KAAd;AAAqBC,gBAAM,EAAE;AAA7B,SAAjC,EAAsEzB,KAAK,IAAG;AAC5E,cAAIA,KAAJ,EAAW;AACT,mBAAOT,QAAQ,CAACS,KAAD,CAAf;AACD;;AAEDT,kBAAQ;AACT,SAND;AAOA;AACD;;AACD,aAAOA,QAAQ,CAACS,KAAD,CAAf;AACD;;AAED,QAAI0B,cAAc,GAAG,KAArB;;AACA,QAAIP,OAAJ,EAAa;AACXA,aAAO,CAACQ,OAAR,CAAiBP,KAAD,IAAoB;AAClC,YAAIA,KAAK,CAACQ,GAAV,EAAe;AACb,gBAAMC,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYT,KAAK,CAACQ,GAAlB,CAAb;;AACA,cAAIC,IAAI,CAACrD,MAAL,KAAgB,CAAhB,IAAqB4C,KAAK,CAACQ,GAAN,CAAU7B,QAAV,KAAuB,CAA5C,IAAiDqB,KAAK,CAACQ,GAAN,CAAUnD,CAAV,KAAgB,CAArE,EAAwE;AACtEiD,0BAAc,GAAG,IAAjB;AACD;AACF;AACF,OAPD;AAQD;;AAED,QAAIA,cAAJ,EAAoB;AAClBnC,cAAQ;AACT,KAFD,MAEO;AACL6B,WAAK,GAAG;AAAErB,gBAAQ,EAAE,CAAZ;AAAetB,SAAC,EAAE;AAAlB,OAAR;AACA,YAAMsD,mBAAmB,GAAGC,eAAe,CAACtB,MAAD,CAA3C;AAEAA,YAAM,CAACjD,MAAP,CAAc8D,WAAd,CACEH,KADF,EAEE,EACE,GAAGW,mBADL;AAEEP,kBAAU,EAAE,IAFd;AAGEC,cAAM,EAAE;AAHV,OAFF,EAOElC,QAPF;AASD;AACF,GA9CD;AA+CD;;AAED,SAAS0C,SAAT,CAAmBvB,MAAnB,EAAoDnB,QAApD,EAAuE;AACrE,MAAImB,MAAM,CAACzC,IAAX,EAAiB,OAAO,IAAP;;AACjB,MAAIyC,MAAM,CAAC/B,KAAP,CAAaC,SAAb,IAA0B8B,MAAM,CAAC/B,KAAP,CAAaE,mBAAb,KAAqC,CAA/D,IAAoE,CAAC6B,MAAM,CAAC/B,KAAP,CAAaG,OAAtF,EAA+F;AAC7F;AACA4B,UAAM,CAACzC,IAAP,GAAc,IAAd,CAF6F,CAG7F;;AACA,UAAMiE,QAAQ,GAAGC,cAAc,CAC7BzB,MAAM,CAACxC,EADsB,EAE7BwC,MAAM,CAAClC,MAFsB,EAG7BkC,MAAM,CAACtC,cAHsB,EAI7BsC,MAAM,CAACnD,QAJsB,EAK7BmD,MAAM,CAAClD,OAAP,CAAe4E,WALc,EAM7B1B,MAAM,CAAClD,OAAP,CAAe6E,OANc,EAO7B3B,MAAM,CAAClD,OAAP,CAAe8E,QAPc,CAA/B;;AAUA,QAAInC,YAAY,CAACO,MAAD,EAASnB,QAAT,CAAhB,EAAoC;AAClC,aAAO,KAAP;AACD;;AAEDmB,UAAM,CAAC9C,KAAP,CAAa2E,SAAb,CAAuBL,QAAvB,EAAiCF,eAAe,CAACtB,MAAD,CAAhD,EAA2DV,KAAD,IAAqB;AAC7E,UAAIA,KAAJ,EAAW;AACT,eAAOS,aAAa,CAACC,MAAD,EAASV,KAAT,EAAgBT,QAAhB,CAApB;AACD;;AACDmB,YAAM,CAACvB,IAAP,CAAYhC,uBAAuB,CAACkD,MAApC,EAA4C6B,QAA5C;AACAxB,YAAM,CAACvB,IAAP,CAAYhC,uBAAuB,CAACqF,KAApC;AACD,KAND;AAQA,WAAO,IAAP;AACD;;AAED,SAAO,KAAP;AACD;;AAED,SAASvD,YAAT,CAAsByB,MAAtB,EAAuDnB,QAAvD,EAAyE;AACvEmB,QAAM,CAAC9C,KAAP,CAAa6E,OAAb,CAAqB,EAArB,EAAyB;AAAEC,cAAU,EAAE;AAAE3B,SAAG,EAAE;AAAP;AAAd,GAAzB,EAAqD,CAACf,KAAD,EAAQ2C,GAAR,KAAe;AAClE,QAAI3C,KAAJ,EAAW;AACT,aAAOT,QAAQ,CAACS,KAAD,CAAf;AACD;;AACD,QAAI2C,GAAJ,EAAS;AACP,aAAOpD,QAAQ,EAAf;AACD;;AAEDmB,UAAM,CAAC9C,KAAP,CAAaqD,WAAb,GAA2BC,OAA3B,CAAmC,CAAClB,KAAD,EAAmBmB,OAAnB,KAAyC;AAC1E,UAAIC,KAAJ;;AACA,UAAIpB,KAAJ,EAAW;AACT;AACA,YAAIA,KAAK,YAAYH,kBAAjB,IAA+BG,KAAK,CAACqB,IAAN,KAAexB,4BAAoByB,iBAAtE,EAAyF;AACvFF,eAAK,GAAG;AAAE7D,oBAAQ,EAAE,CAAZ;AAAeqF,sBAAU,EAAE;AAA3B,WAAR;AACAlC,gBAAM,CAAC9C,KAAP,CAAa2D,WAAb,CAAyBH,KAAzB,EAAgC;AAAEI,sBAAU,EAAE;AAAd,WAAhC,EAAwDxB,KAAD,IAAqB;AAC1E,gBAAIA,KAAJ,EAAW;AACT,qBAAOT,QAAQ,CAACS,KAAD,CAAf;AACD;;AAEDgB,4BAAgB,CAACN,MAAD,EAASnB,QAAT,CAAhB;AACD,WAND;AAOA;AACD;;AACD,eAAOA,QAAQ,CAACS,KAAD,CAAf;AACD;;AAED,UAAI6C,YAAY,GAAG,KAAnB;;AACA,UAAI1B,OAAJ,EAAa;AACXA,eAAO,CAACQ,OAAR,CAAiBP,KAAD,IAAoB;AAClC,gBAAMS,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYT,KAAK,CAACQ,GAAlB,CAAb;;AACA,cAAIC,IAAI,CAACrD,MAAL,KAAgB,CAAhB,IAAqB4C,KAAK,CAACQ,GAAN,CAAUrE,QAAV,KAAuB,CAA5C,IAAiD6D,KAAK,CAACQ,GAAN,CAAUgB,UAAV,KAAyB,CAA9E,EAAiF;AAC/EC,wBAAY,GAAG,IAAf;AACD;AACF,SALD;AAMD;;AAED,UAAIA,YAAJ,EAAkB;AAChB7B,wBAAgB,CAACN,MAAD,EAASnB,QAAT,CAAhB;AACD,OAFD,MAEO;AACL6B,aAAK,GAAG;AAAE7D,kBAAQ,EAAE,CAAZ;AAAeqF,oBAAU,EAAE;AAA3B,SAAR;AAEA,cAAMb,mBAAmB,GAAGC,eAAe,CAACtB,MAAD,CAA3C;AAEAA,cAAM,CAAC9C,KAAP,CAAa2D,WAAb,CACEH,KADF,EAEE,EACE,GAAGW,mBADL;AAEEP,oBAAU,EAAE;AAFd,SAFF,EAMGxB,KAAD,IAAqB;AACnB,cAAIA,KAAJ,EAAW;AACT,mBAAOT,QAAQ,CAACS,KAAD,CAAf;AACD;;AAEDgB,0BAAgB,CAACN,MAAD,EAASnB,QAAT,CAAhB;AACD,SAZH;AAcD;AACF,KAlDD;AAmDD,GA3DD;AA4DD;;AAED,SAAS4C,cAAT,CACEpB,GADF,EAEEvC,MAFF,EAGEsE,SAHF,EAIEvF,QAJF,EAKE6E,WALF,EAMEC,OANF,EAOEC,QAPF,EAOqB;AAEnB,QAAMS,GAAG,GAAe;AACtBhC,OADsB;AAEtBvC,UAFsB;AAGtBsE,aAHsB;AAItBF,cAAU,EAAE,IAAII,IAAJ,EAJU;AAKtBzF;AALsB,GAAxB;;AAQA,MAAI6E,WAAJ,EAAiB;AACfW,OAAG,CAACX,WAAJ,GAAkBA,WAAlB;AACD;;AAED,MAAIC,OAAJ,EAAa;AACXU,OAAG,CAACV,OAAJ,GAAcA,OAAd;AACD;;AAED,MAAIC,QAAJ,EAAc;AACZS,OAAG,CAACT,QAAJ,GAAeA,QAAf;AACD;;AAED,SAAOS,GAAP;AACD;;AAED,SAASpD,OAAT,CACEe,MADF,EAEErB,KAFF,EAGEG,QAHF,EAIED,QAJF,EAI2B;AAEzB,MAAIY,YAAY,CAACO,MAAD,EAASnB,QAAT,CAAhB,EAAoC;AAClC,WAAO,KAAP;AACD;;AAED,QAAM0D,QAAQ,GAAG3E,MAAM,CAAC4E,QAAP,CAAgB7D,KAAhB,IAAyBA,KAAzB,GAAiCf,MAAM,CAAC6E,IAAP,CAAY9D,KAAZ,EAAmBG,QAAnB,CAAlD;AAEAkB,QAAM,CAAClC,MAAP,IAAiByE,QAAQ,CAACzE,MAA1B,CARyB,CAUzB;;AACA,MAAIkC,MAAM,CAAChC,GAAP,GAAauE,QAAQ,CAACzE,MAAtB,GAA+BkC,MAAM,CAACtC,cAA1C,EAA0D;AACxD6E,YAAQ,CAACG,IAAT,CAAc1C,MAAM,CAACrC,UAArB,EAAiCqC,MAAM,CAAChC,GAAxC;AACAgC,UAAM,CAAChC,GAAP,IAAcuE,QAAQ,CAACzE,MAAvB;AAEAe,YAAQ,IAAIA,QAAQ,EAApB,CAJwD,CAMxD;AACA;AACA;;AACA,WAAO,IAAP;AACD,GArBwB,CAuBzB;AACA;;;AACA,MAAI8D,iBAAiB,GAAGJ,QAAQ,CAACzE,MAAjC;AACA,MAAI8E,cAAc,GAAW5C,MAAM,CAACtC,cAAP,GAAwBsC,MAAM,CAAChC,GAA5D;AACA,MAAI6E,SAAS,GAAGC,IAAI,CAACC,GAAL,CAASH,cAAT,EAAyBL,QAAQ,CAACzE,MAAlC,CAAhB;AACA,MAAIK,mBAAmB,GAAG,CAA1B;;AACA,SAAOwE,iBAAiB,GAAG,CAA3B,EAA8B;AAC5B,UAAMK,WAAW,GAAGT,QAAQ,CAACzE,MAAT,GAAkB6E,iBAAtC;AACAJ,YAAQ,CAACG,IAAT,CAAc1C,MAAM,CAACrC,UAArB,EAAiCqC,MAAM,CAAChC,GAAxC,EAA6CgF,WAA7C,EAA0DA,WAAW,GAAGH,SAAxE;AACA7C,UAAM,CAAChC,GAAP,IAAc6E,SAAd;AACAD,kBAAc,IAAIC,SAAlB;AACA,QAAIZ,GAAJ;;AACA,QAAIW,cAAc,KAAK,CAAvB,EAA0B;AACxBX,SAAG,GAAG/B,cAAc,CAACF,MAAM,CAACxC,EAAR,EAAYwC,MAAM,CAACjC,CAAnB,EAAsBH,MAAM,CAAC6E,IAAP,CAAYzC,MAAM,CAACrC,UAAnB,CAAtB,CAApB;AACA,QAAEqC,MAAM,CAAC/B,KAAP,CAAaE,mBAAf;AACA,QAAEA,mBAAF;;AAEA,UAAIsB,YAAY,CAACO,MAAD,EAASnB,QAAT,CAAhB,EAAoC;AAClC,eAAO,KAAP;AACD;;AAEDmB,YAAM,CAACjD,MAAP,CAAc8E,SAAd,CAAwBI,GAAxB,EAA6BX,eAAe,CAACtB,MAAD,CAA5C,EAAuDV,KAAD,IAAqB;AACzE,YAAIA,KAAJ,EAAW;AACT,iBAAOS,aAAa,CAACC,MAAD,EAASV,KAAT,CAApB;AACD;;AACD,UAAEU,MAAM,CAAC/B,KAAP,CAAaE,mBAAf;AACA,UAAEA,mBAAF;;AAEA,YAAI,CAACA,mBAAL,EAA0B;AACxB6B,gBAAM,CAACvB,IAAP,CAAY,OAAZ,EAAqBwD,GAArB;AACApD,kBAAQ,IAAIA,QAAQ,EAApB;AACA0C,mBAAS,CAACvB,MAAD,CAAT;AACD;AACF,OAZD;AAcA4C,oBAAc,GAAG5C,MAAM,CAACtC,cAAxB;AACAsC,YAAM,CAAChC,GAAP,GAAa,CAAb;AACA,QAAEgC,MAAM,CAACjC,CAAT;AACD;;AACD4E,qBAAiB,IAAIE,SAArB;AACAA,aAAS,GAAGC,IAAI,CAACC,GAAL,CAASH,cAAT,EAAyBD,iBAAzB,CAAZ;AACD,GAhEwB,CAkEzB;AACA;AACA;;;AACA,SAAO,KAAP;AACD;;AAED,SAASrB,eAAT,CAAyBtB,MAAzB,EAAwD;AACtD,QAAMiD,GAAG,GAAwB,EAAjC;;AACA,MAAIjD,MAAM,CAAC5C,YAAX,EAAyB;AACvB6F,OAAG,CAAC7F,YAAJ,GAAmB;AACjB8F,OAAC,EAAElD,MAAM,CAAC5C,YAAP,CAAoB8F,CADN;AAEjBC,cAAQ,EAAEnD,MAAM,CAAC5C,YAAP,CAAoB+F,QAFb;AAGjBC,OAAC,EAAEpD,MAAM,CAAC5C,YAAP,CAAoBgG;AAHN,KAAnB;AAKD;;AACD,SAAOH,GAAP;AACD;;AAED,SAASjE,cAAT,CACEgB,MADF,EAEEnB,QAFF,EAEqC;AAEnC,MAAImB,MAAM,CAACpD,MAAP,CAAcI,CAAd,CAAgBwB,cAApB,EAAoC;AAClC,WAAOK,QAAQ,CAAC,KAAD,CAAf;AACD;;AAEDmB,QAAM,CAACpD,MAAP,CAAc8C,IAAd,CAAmB,OAAnB,EAA4B,MAAK;AAC/Bb,YAAQ,CAAC,IAAD,CAAR;AACD,GAFD;AAIA,SAAO,IAAP;AACD;;AAED,SAASgB,YAAT,CAAsBG,MAAtB,EAAuDnB,QAAvD,EAA0E;AACxE;AACA,MAAImB,MAAM,CAAChC,GAAP,KAAe,CAAnB,EAAsB;AACpB,WAAOuD,SAAS,CAACvB,MAAD,EAASnB,QAAT,CAAhB;AACD;;AAED,IAAEmB,MAAM,CAAC/B,KAAP,CAAaE,mBAAf,CANwE,CAQxE;AACA;;AACA,QAAMkF,OAAO,GAAGzF,MAAM,CAACC,KAAP,CAAamC,MAAM,CAAChC,GAApB,CAAhB;AACAgC,QAAM,CAACrC,UAAP,CAAkB+E,IAAlB,CAAuBW,OAAvB,EAAgC,CAAhC,EAAmC,CAAnC,EAAsCrD,MAAM,CAAChC,GAA7C;AACA,QAAMiE,GAAG,GAAG/B,cAAc,CAACF,MAAM,CAACxC,EAAR,EAAYwC,MAAM,CAACjC,CAAnB,EAAsBsF,OAAtB,CAA1B,CAZwE,CAcxE;;AACA,MAAI5D,YAAY,CAACO,MAAD,EAASnB,QAAT,CAAhB,EAAoC;AAClC,WAAO,KAAP;AACD;;AAEDmB,QAAM,CAACjD,MAAP,CAAc8E,SAAd,CAAwBI,GAAxB,EAA6BX,eAAe,CAACtB,MAAD,CAA5C,EAAuDV,KAAD,IAAqB;AACzE,QAAIA,KAAJ,EAAW;AACT,aAAOS,aAAa,CAACC,MAAD,EAASV,KAAT,CAApB;AACD;;AACD,MAAEU,MAAM,CAAC/B,KAAP,CAAaE,mBAAf;AACAoD,aAAS,CAACvB,MAAD,CAAT;AACD,GAND;AAOA,SAAO,IAAP;AACD;;AAED,SAASP,YAAT,CAAsBO,MAAtB,EAAuDnB,QAAvD,EAAgF;AAC9E,MAAImB,MAAM,CAAC/B,KAAP,CAAaI,OAAjB,EAA0B;AACxB,QAAI,OAAOQ,QAAP,KAAoB,UAAxB,EAAoC;AAClC;AACAA,cAAQ,CAAC,IAAIM,qBAAJ,CAAkB,yBAAlB,CAAD,CAAR;AACD;;AACD,WAAO,IAAP;AACD;;AACD,SAAO,KAAP;AACD","names":["GridFSBucketWriteStream","stream_1","constructor","bucket","filename","options","chunks","s","_chunksCollection","files","_filesCollection","writeConcern","write_concern_1","fromOptions","done","id","bson_1","chunkSizeBytes","bufToStore","Buffer","alloc","length","n","pos","state","streamEnd","outstandingRequests","errored","aborted","calledOpenUploadStream","checkIndexes","checkedIndexes","emit","write","chunk","encodingOrCallback","callback","encoding","undefined","waitForIndexes","doWrite","abort","error_1","deleteMany","files_id","error","end","chunkOrCallback","checkAborted","once","FINISH","result","writeRemnant","exports","__handleError","stream","ERROR","createChunkDoc","filesId","data","_id","checkChunksIndex","listIndexes","toArray","indexes","index","code","NamespaceNotFound","createIndex","background","unique","hasChunksIndex","forEach","key","keys","Object","writeConcernOptions","getWriteOptions","checkDone","filesDoc","createFilesDoc","contentType","aliases","metadata","insertOne","CLOSE","findOne","projection","doc","uploadDate","hasFileIndex","chunkSize","ret","Date","inputBuf","isBuffer","from","copy","inputBufRemaining","spaceRemaining","numToCopy","Math","min","inputBufPos","obj","w","wtimeout","j","remnant"],"sources":["/Users/santiago/Documents/tulipan1637/iot-sensor/node_modules/mongodb/src/gridfs/upload.ts"],"sourcesContent":["import { Writable } from 'stream';\n\nimport type { Document } from '../bson';\nimport { ObjectId } from '../bson';\nimport type { Collection } from '../collection';\nimport { AnyError, MongoAPIError, MONGODB_ERROR_CODES, MongoError } from '../error';\nimport { Callback, maybePromise } from '../utils';\nimport type { WriteConcernOptions } from '../write_concern';\nimport { WriteConcern } from './../write_concern';\nimport type { GridFSFile } from './download';\nimport type { GridFSBucket } from './index';\n\n/** @public */\nexport interface GridFSChunk {\n  _id: ObjectId;\n  files_id: ObjectId;\n  n: number;\n  data: Buffer | Uint8Array;\n}\n\n/** @public */\nexport interface GridFSBucketWriteStreamOptions extends WriteConcernOptions {\n  /** Overwrite this bucket's chunkSizeBytes for this file */\n  chunkSizeBytes?: number;\n  /** Custom file id for the GridFS file. */\n  id?: ObjectId;\n  /** Object to store in the file document's `metadata` field */\n  metadata?: Document;\n  /** String to store in the file document's `contentType` field */\n  contentType?: string;\n  /** Array of strings to store in the file document's `aliases` field */\n  aliases?: string[];\n}\n\n/**\n * A writable stream that enables you to write buffers to GridFS.\n *\n * Do not instantiate this class directly. Use `openUploadStream()` instead.\n * @public\n */\nexport class GridFSBucketWriteStream extends Writable implements NodeJS.WritableStream {\n  bucket: GridFSBucket;\n  chunks: Collection<GridFSChunk>;\n  filename: string;\n  files: Collection<GridFSFile>;\n  options: GridFSBucketWriteStreamOptions;\n  done: boolean;\n  id: ObjectId;\n  chunkSizeBytes: number;\n  bufToStore: Buffer;\n  length: number;\n  n: number;\n  pos: number;\n  state: {\n    streamEnd: boolean;\n    outstandingRequests: number;\n    errored: boolean;\n    aborted: boolean;\n  };\n  writeConcern?: WriteConcern;\n\n  /** @event */\n  static readonly CLOSE = 'close';\n  /** @event */\n  static readonly ERROR = 'error';\n  /**\n   * `end()` was called and the write stream successfully wrote the file metadata and all the chunks to MongoDB.\n   * @event\n   */\n  static readonly FINISH = 'finish';\n\n  /** @internal\n   * @param bucket - Handle for this stream's corresponding bucket\n   * @param filename - The value of the 'filename' key in the files doc\n   * @param options - Optional settings.\n   */\n  constructor(bucket: GridFSBucket, filename: string, options?: GridFSBucketWriteStreamOptions) {\n    super();\n\n    options = options ?? {};\n    this.bucket = bucket;\n    this.chunks = bucket.s._chunksCollection;\n    this.filename = filename;\n    this.files = bucket.s._filesCollection;\n    this.options = options;\n    this.writeConcern = WriteConcern.fromOptions(options) || bucket.s.options.writeConcern;\n    // Signals the write is all done\n    this.done = false;\n\n    this.id = options.id ? options.id : new ObjectId();\n    // properly inherit the default chunksize from parent\n    this.chunkSizeBytes = options.chunkSizeBytes || this.bucket.s.options.chunkSizeBytes;\n    this.bufToStore = Buffer.alloc(this.chunkSizeBytes);\n    this.length = 0;\n    this.n = 0;\n    this.pos = 0;\n    this.state = {\n      streamEnd: false,\n      outstandingRequests: 0,\n      errored: false,\n      aborted: false\n    };\n\n    if (!this.bucket.s.calledOpenUploadStream) {\n      this.bucket.s.calledOpenUploadStream = true;\n\n      checkIndexes(this, () => {\n        this.bucket.s.checkedIndexes = true;\n        this.bucket.emit('index');\n      });\n    }\n  }\n\n  /**\n   * Write a buffer to the stream.\n   *\n   * @param chunk - Buffer to write\n   * @param encodingOrCallback - Optional encoding for the buffer\n   * @param callback - Function to call when the chunk was added to the buffer, or if the entire chunk was persisted to MongoDB if this chunk caused a flush.\n   * @returns False if this write required flushing a chunk to MongoDB. True otherwise.\n   */\n  write(chunk: Buffer | string): boolean;\n  write(chunk: Buffer | string, callback: Callback<void>): boolean;\n  write(chunk: Buffer | string, encoding: BufferEncoding | undefined): boolean;\n  write(\n    chunk: Buffer | string,\n    encoding: BufferEncoding | undefined,\n    callback: Callback<void>\n  ): boolean;\n  write(\n    chunk: Buffer | string,\n    encodingOrCallback?: Callback<void> | BufferEncoding,\n    callback?: Callback<void>\n  ): boolean {\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback = typeof encodingOrCallback === 'function' ? encodingOrCallback : callback;\n    return waitForIndexes(this, () => doWrite(this, chunk, encoding, callback));\n  }\n\n  // TODO(NODE-3405): Refactor this with maybePromise and MongoStreamClosedError\n  /**\n   * Places this write stream into an aborted state (all future writes fail)\n   * and deletes all chunks that have already been written.\n   *\n   * @param callback - called when chunks are successfully removed or error occurred\n   */\n  abort(): Promise<void>;\n  abort(callback: Callback<void>): void;\n  abort(callback?: Callback<void>): Promise<void> | void {\n    return maybePromise(callback, callback => {\n      if (this.state.streamEnd) {\n        // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n        return callback(new MongoAPIError('Cannot abort a stream that has already completed'));\n      }\n\n      if (this.state.aborted) {\n        // TODO(NODE-3485): Replace with MongoGridFSStreamClosed\n        return callback(new MongoAPIError('Cannot call abort() on a stream twice'));\n      }\n\n      this.state.aborted = true;\n      this.chunks.deleteMany({ files_id: this.id }, error => callback(error));\n    });\n  }\n\n  /**\n   * Tells the stream that no more data will be coming in. The stream will\n   * persist the remaining data to MongoDB, write the files document, and\n   * then emit a 'finish' event.\n   *\n   * @param chunk - Buffer to write\n   * @param encoding - Optional encoding for the buffer\n   * @param callback - Function to call when all files and chunks have been persisted to MongoDB\n   */\n  end(): this;\n  end(chunk: Buffer): this;\n  end(callback: Callback<GridFSFile | void>): this;\n  end(chunk: Buffer, callback: Callback<GridFSFile | void>): this;\n  end(chunk: Buffer, encoding: BufferEncoding): this;\n  end(\n    chunk: Buffer,\n    encoding: BufferEncoding | undefined,\n    callback: Callback<GridFSFile | void>\n  ): this;\n  end(\n    chunkOrCallback?: Buffer | Callback<GridFSFile | void>,\n    encodingOrCallback?: BufferEncoding | Callback<GridFSFile | void>,\n    callback?: Callback<GridFSFile | void>\n  ): this {\n    const chunk = typeof chunkOrCallback === 'function' ? undefined : chunkOrCallback;\n    const encoding = typeof encodingOrCallback === 'function' ? undefined : encodingOrCallback;\n    callback =\n      typeof chunkOrCallback === 'function'\n        ? chunkOrCallback\n        : typeof encodingOrCallback === 'function'\n        ? encodingOrCallback\n        : callback;\n\n    if (checkAborted(this, callback)) return this;\n\n    this.state.streamEnd = true;\n\n    if (callback) {\n      this.once(GridFSBucketWriteStream.FINISH, (result: GridFSFile) => {\n        if (callback) callback(undefined, result);\n      });\n    }\n\n    if (!chunk) {\n      waitForIndexes(this, () => !!writeRemnant(this));\n      return this;\n    }\n\n    this.write(chunk, encoding, () => {\n      writeRemnant(this);\n    });\n\n    return this;\n  }\n}\n\nfunction __handleError(\n  stream: GridFSBucketWriteStream,\n  error: AnyError,\n  callback?: Callback\n): void {\n  if (stream.state.errored) {\n    return;\n  }\n  stream.state.errored = true;\n  if (callback) {\n    return callback(error);\n  }\n  stream.emit(GridFSBucketWriteStream.ERROR, error);\n}\n\nfunction createChunkDoc(filesId: ObjectId, n: number, data: Buffer): GridFSChunk {\n  return {\n    _id: new ObjectId(),\n    files_id: filesId,\n    n,\n    data\n  };\n}\n\nfunction checkChunksIndex(stream: GridFSBucketWriteStream, callback: Callback): void {\n  stream.chunks.listIndexes().toArray((error?: AnyError, indexes?: Document[]) => {\n    let index: { files_id: number; n: number };\n    if (error) {\n      // Collection doesn't exist so create index\n      if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\n        index = { files_id: 1, n: 1 };\n        stream.chunks.createIndex(index, { background: false, unique: true }, error => {\n          if (error) {\n            return callback(error);\n          }\n\n          callback();\n        });\n        return;\n      }\n      return callback(error);\n    }\n\n    let hasChunksIndex = false;\n    if (indexes) {\n      indexes.forEach((index: Document) => {\n        if (index.key) {\n          const keys = Object.keys(index.key);\n          if (keys.length === 2 && index.key.files_id === 1 && index.key.n === 1) {\n            hasChunksIndex = true;\n          }\n        }\n      });\n    }\n\n    if (hasChunksIndex) {\n      callback();\n    } else {\n      index = { files_id: 1, n: 1 };\n      const writeConcernOptions = getWriteOptions(stream);\n\n      stream.chunks.createIndex(\n        index,\n        {\n          ...writeConcernOptions,\n          background: true,\n          unique: true\n        },\n        callback\n      );\n    }\n  });\n}\n\nfunction checkDone(stream: GridFSBucketWriteStream, callback?: Callback): boolean {\n  if (stream.done) return true;\n  if (stream.state.streamEnd && stream.state.outstandingRequests === 0 && !stream.state.errored) {\n    // Set done so we do not trigger duplicate createFilesDoc\n    stream.done = true;\n    // Create a new files doc\n    const filesDoc = createFilesDoc(\n      stream.id,\n      stream.length,\n      stream.chunkSizeBytes,\n      stream.filename,\n      stream.options.contentType,\n      stream.options.aliases,\n      stream.options.metadata\n    );\n\n    if (checkAborted(stream, callback)) {\n      return false;\n    }\n\n    stream.files.insertOne(filesDoc, getWriteOptions(stream), (error?: AnyError) => {\n      if (error) {\n        return __handleError(stream, error, callback);\n      }\n      stream.emit(GridFSBucketWriteStream.FINISH, filesDoc);\n      stream.emit(GridFSBucketWriteStream.CLOSE);\n    });\n\n    return true;\n  }\n\n  return false;\n}\n\nfunction checkIndexes(stream: GridFSBucketWriteStream, callback: Callback): void {\n  stream.files.findOne({}, { projection: { _id: 1 } }, (error, doc) => {\n    if (error) {\n      return callback(error);\n    }\n    if (doc) {\n      return callback();\n    }\n\n    stream.files.listIndexes().toArray((error?: AnyError, indexes?: Document) => {\n      let index: { filename: number; uploadDate: number };\n      if (error) {\n        // Collection doesn't exist so create index\n        if (error instanceof MongoError && error.code === MONGODB_ERROR_CODES.NamespaceNotFound) {\n          index = { filename: 1, uploadDate: 1 };\n          stream.files.createIndex(index, { background: false }, (error?: AnyError) => {\n            if (error) {\n              return callback(error);\n            }\n\n            checkChunksIndex(stream, callback);\n          });\n          return;\n        }\n        return callback(error);\n      }\n\n      let hasFileIndex = false;\n      if (indexes) {\n        indexes.forEach((index: Document) => {\n          const keys = Object.keys(index.key);\n          if (keys.length === 2 && index.key.filename === 1 && index.key.uploadDate === 1) {\n            hasFileIndex = true;\n          }\n        });\n      }\n\n      if (hasFileIndex) {\n        checkChunksIndex(stream, callback);\n      } else {\n        index = { filename: 1, uploadDate: 1 };\n\n        const writeConcernOptions = getWriteOptions(stream);\n\n        stream.files.createIndex(\n          index,\n          {\n            ...writeConcernOptions,\n            background: false\n          },\n          (error?: AnyError) => {\n            if (error) {\n              return callback(error);\n            }\n\n            checkChunksIndex(stream, callback);\n          }\n        );\n      }\n    });\n  });\n}\n\nfunction createFilesDoc(\n  _id: ObjectId,\n  length: number,\n  chunkSize: number,\n  filename: string,\n  contentType?: string,\n  aliases?: string[],\n  metadata?: Document\n): GridFSFile {\n  const ret: GridFSFile = {\n    _id,\n    length,\n    chunkSize,\n    uploadDate: new Date(),\n    filename\n  };\n\n  if (contentType) {\n    ret.contentType = contentType;\n  }\n\n  if (aliases) {\n    ret.aliases = aliases;\n  }\n\n  if (metadata) {\n    ret.metadata = metadata;\n  }\n\n  return ret;\n}\n\nfunction doWrite(\n  stream: GridFSBucketWriteStream,\n  chunk: Buffer | string,\n  encoding?: BufferEncoding,\n  callback?: Callback<void>\n): boolean {\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n\n  const inputBuf = Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk, encoding);\n\n  stream.length += inputBuf.length;\n\n  // Input is small enough to fit in our buffer\n  if (stream.pos + inputBuf.length < stream.chunkSizeBytes) {\n    inputBuf.copy(stream.bufToStore, stream.pos);\n    stream.pos += inputBuf.length;\n\n    callback && callback();\n\n    // Note that we reverse the typical semantics of write's return value\n    // to be compatible with node's `.pipe()` function.\n    // True means client can keep writing.\n    return true;\n  }\n\n  // Otherwise, buffer is too big for current chunk, so we need to flush\n  // to MongoDB.\n  let inputBufRemaining = inputBuf.length;\n  let spaceRemaining: number = stream.chunkSizeBytes - stream.pos;\n  let numToCopy = Math.min(spaceRemaining, inputBuf.length);\n  let outstandingRequests = 0;\n  while (inputBufRemaining > 0) {\n    const inputBufPos = inputBuf.length - inputBufRemaining;\n    inputBuf.copy(stream.bufToStore, stream.pos, inputBufPos, inputBufPos + numToCopy);\n    stream.pos += numToCopy;\n    spaceRemaining -= numToCopy;\n    let doc: GridFSChunk;\n    if (spaceRemaining === 0) {\n      doc = createChunkDoc(stream.id, stream.n, Buffer.from(stream.bufToStore));\n      ++stream.state.outstandingRequests;\n      ++outstandingRequests;\n\n      if (checkAborted(stream, callback)) {\n        return false;\n      }\n\n      stream.chunks.insertOne(doc, getWriteOptions(stream), (error?: AnyError) => {\n        if (error) {\n          return __handleError(stream, error);\n        }\n        --stream.state.outstandingRequests;\n        --outstandingRequests;\n\n        if (!outstandingRequests) {\n          stream.emit('drain', doc);\n          callback && callback();\n          checkDone(stream);\n        }\n      });\n\n      spaceRemaining = stream.chunkSizeBytes;\n      stream.pos = 0;\n      ++stream.n;\n    }\n    inputBufRemaining -= numToCopy;\n    numToCopy = Math.min(spaceRemaining, inputBufRemaining);\n  }\n\n  // Note that we reverse the typical semantics of write's return value\n  // to be compatible with node's `.pipe()` function.\n  // False means the client should wait for the 'drain' event.\n  return false;\n}\n\nfunction getWriteOptions(stream: GridFSBucketWriteStream): WriteConcernOptions {\n  const obj: WriteConcernOptions = {};\n  if (stream.writeConcern) {\n    obj.writeConcern = {\n      w: stream.writeConcern.w,\n      wtimeout: stream.writeConcern.wtimeout,\n      j: stream.writeConcern.j\n    };\n  }\n  return obj;\n}\n\nfunction waitForIndexes(\n  stream: GridFSBucketWriteStream,\n  callback: (res: boolean) => boolean\n): boolean {\n  if (stream.bucket.s.checkedIndexes) {\n    return callback(false);\n  }\n\n  stream.bucket.once('index', () => {\n    callback(true);\n  });\n\n  return true;\n}\n\nfunction writeRemnant(stream: GridFSBucketWriteStream, callback?: Callback): boolean {\n  // Buffer is empty, so don't bother to insert\n  if (stream.pos === 0) {\n    return checkDone(stream, callback);\n  }\n\n  ++stream.state.outstandingRequests;\n\n  // Create a new buffer to make sure the buffer isn't bigger than it needs\n  // to be.\n  const remnant = Buffer.alloc(stream.pos);\n  stream.bufToStore.copy(remnant, 0, 0, stream.pos);\n  const doc = createChunkDoc(stream.id, stream.n, remnant);\n\n  // If the stream was aborted, do not write remnant\n  if (checkAborted(stream, callback)) {\n    return false;\n  }\n\n  stream.chunks.insertOne(doc, getWriteOptions(stream), (error?: AnyError) => {\n    if (error) {\n      return __handleError(stream, error);\n    }\n    --stream.state.outstandingRequests;\n    checkDone(stream);\n  });\n  return true;\n}\n\nfunction checkAborted(stream: GridFSBucketWriteStream, callback?: Callback<void>): boolean {\n  if (stream.state.aborted) {\n    if (typeof callback === 'function') {\n      // TODO(NODE-3485): Replace with MongoGridFSStreamClosedError\n      callback(new MongoAPIError('Stream has been aborted'));\n    }\n    return true;\n  }\n  return false;\n}\n"]},"metadata":{},"sourceType":"script"}